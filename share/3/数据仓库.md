# 数据仓库

## 定义

stg：临时层，保存异构的源系统集成过来的表 

ods：贴源层，保存源系统细节数据 

dwd：模型层, 构建业务数据模型

app：应用层，保存业务报表的数据表



## 原因

用空间换时间，通过大量的预处理来提升应用系统的用户体验，因此数据仓库会存在大量冗余的数据.

如果不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，工作量巨大.

通过数据分层管理可以简化数据清洗的过程，因为把原来一步的工作分到了多个步骤去完成，相当于把一个复杂的工作拆成了多个简单的工作，把一个大的黑盒变成了一个白盒，每一层的处理逻辑都相对简单和容易理解，这样我们比较容易保证每一个步骤的正确性，当数据发生错误的时候，往往我们只需要局部调整某个步骤即可。



## Q&A

1 表设计有哪些规范或细节要注意？

命名方式（每家公司标准都不一样），文件格式（txtfile居多，orc，parquet视情况定），删建表时记得加if (not) exists

字段类型我们主要用的就是string、bigint、double，很少用timestamp，时间类型用string存储也是一样处理的，之前也用过timestamp类型，踩了很多坑（主要还是不熟悉），数字类型的tinyint、smallint、int、bigint这些就是值的大小区别，没有很明确或不确定的时候直接string就好
有一点要注意，float和double由于精度保留不同，在hive中会导致存储的值有变化，所以一定要注意类型统一



2 文件存储时一个文件一般多大？1g还是更大？有没有什么一般性策略？文件太小占用过多集群资源，影响任务运行效率，一个分区下文件一般多少？

小文件那个问题，可以在hive中进行set配置，默认的就是256M（我们很少去动这些配置，都是跑不动了，或者跑得很慢，才会去尝试调整）

3 数据保存和清除策略怎么样处理？

数据清理几乎针对的都是分区数据，直接搞一个任务或者在原来的计算任务最后部分，drop分区就好，这边要注意的就是最好加一个offset，适当增加缓冲时间

4 数据发生端的数据错了，如何同步更新到app层

重跑呗，从哪边错了，从哪边开始重跑，这里有些细节，在创建jenkins job或者写脚本的时候，多考虑下参数设置，良好的参数设置可以极大减少后期维护工作量



5 数仓中的去重与排序(那么去重在什么时候做呢？还有去重有哪些优化。比如对订单号这种值很多的字段去重。内部肯定是做排序了(或者其他方式，不确定怎么去重)，有哪些策略。)

hive里面存的结果数据一般情况不做排序，去重的话我们也很少在stg这边做，stg和ods基本上就是保存的原始数据，不太建议在导入导出过程中处理业务



6 数据质量与一致性保证(除了计日志，丢数据的问题一般出现的原因是什么呢？如何去定位丢的数据呢？)

搞一张日志表，专门记录数据导入导出日志的，如果用kettle的话还可以设置告警策略